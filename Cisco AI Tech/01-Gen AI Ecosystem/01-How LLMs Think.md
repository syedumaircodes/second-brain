# How LLMs think

Large language models like ChatGPT are claimed to have thinking abilities like humans, but their thinking is totally different from our own, LLMs are just glorified prediction engines, they don't understand words and the emotions behind them as they are just calculating the next probable word based on the patterns in their training data.

The model begins its answer by stitching together words with the highest probability and  adds it to the sequence. It nothing more than a fancy autocomplete that's capable of writing entire narratives

By repeating this process, the LLMs generate everything, from simple sentences to complex code and analysis. Their outputs are based on probability and not true knowledge.